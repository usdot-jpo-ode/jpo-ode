package us.dot.its.jpo.ode;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import java.util.Properties;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.utils.Bytes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StoreQueryParameters;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.state.KeyValueStore;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;
import org.springframework.kafka.core.KafkaTemplate;
import us.dot.its.jpo.ode.kafka.OdeKafkaProperties;

/**
 * OdeTimJsonTopology sets up and manages a Kafka Streams topology for
 * processing TIM JSON data from a specified Kafka topic.
 * This class filters incoming TIM messages to retain only those generated by
 * the TMC, storing them in a KTable keyed by each message's UUID.
 * This class provides a query method to retrieve and automatically remove (via
 * tombstone) a TIM message by its UUID, ensuring the KTable remains up-to-date
 * and free of stale entries.
 * The topology is configured using provided Kafka properties and supports both
 * standard and Confluent Kafka deployments.
 */
@Slf4j
public class OdeTimJsonTopology {

  private final KafkaStreams streams;
  private final KafkaTemplate<String, String> tombstonePublisher;

  private String topic;
  private String ktableTopic;

  /**
   * Constructs an instance of OdeTimJsonTopology to set up and manage a Kafka
   * Streams topology for processing TIM JSON data.
   *
   * @param odeKafkaProps the properties containing Kafka configuration, including
   *                      brokers and optional Confluent-specific configuration
   *                      for authentication.
   * @param topic         the Kafka topic from which TIM JSON data is consumed to
   *                      build the topology.
   * @param ktableTopic   the Kafka topic used for the KTable, which stores TIM
   *                      JSON messages keyed by their UUID.
   * @param template      The KafkaTemplate used to publish tombstone messages to
   *                      the topic.
   */
  public OdeTimJsonTopology(OdeKafkaProperties odeKafkaProps, String topic, String ktableTopic,
      KafkaTemplate<String, String> template) {
    Properties streamsProperties = new Properties();
    streamsProperties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, odeKafkaProps.getBrokers());
    streamsProperties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);
    streamsProperties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class);
    streamsProperties.put(StreamsConfig.APPLICATION_ID_CONFIG, "ode-tim-json-topology");

    if ("CONFLUENT".equals(odeKafkaProps.getKafkaType())) {
      streamsProperties.putAll(odeKafkaProps.getConfluent().buildConfluentProperties());
    }

    // Configure RocksDB memory usage
    streamsProperties.put(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG, BoundedMemoryRocksDBConfig.class);

    this.topic = topic;
    this.ktableTopic = ktableTopic;
    this.tombstonePublisher = template;
    streams = new KafkaStreams(buildTopology(), streamsProperties);
    streams.setStateListener(
        (newState, oldState) -> log.info("Transitioning from {} to {}", oldState, newState));
    streams.start();
  }

  public boolean isRunning() {
    return streams.state().equals(KafkaStreams.State.RUNNING);
  }

  /**
   * Builds a Kafka Streams topology for processing TIM JSON data.
   *
   * @return the constructed Kafka Streams topology.
   */
  public Topology buildTopology() {
    StreamsBuilder builder = new StreamsBuilder();
    ObjectMapper objectMapper = new ObjectMapper();

    // Read as KStream, filter to only include TMC generated messages, then write to
    // new topic
    builder.stream(this.topic, Consumed.with(Serdes.String(), Serdes.String()))
        .filter((key, value) -> {
          try {
            // Null values are tombstones, which are needed to remove entries from the
            // KTable
            if (value == null) {
              return true;
            }
            // Parse the JSON and check if the message was generated by the TMC
            JsonNode nodeMetadata = objectMapper.readTree(value).get("metadata");
            boolean isTMCGenerated = "TMC".equals(nodeMetadata.get("recordGeneratedBy").asText());
            log.debug("TMC Generated: {}, Key: {}", isTMCGenerated, key);
            return isTMCGenerated;
          } catch (Exception e) {
            // Don't include unexpected JSON formats in the KTable
            // This is only intended to be a graceful handling of unexpected JSON so logging
            // is set to debug
            log.debug("TIM topology failed to parse JSON for key {}: {}", key, e.getMessage());
            return false;
          }
        }).to(ktableTopic);

    // Create a global KTable from the filtered topic, keyed by UUID. This allows
    // for multi-instance deployments
    builder.globalTable(ktableTopic,
        Consumed.with(Serdes.String(), Serdes.String()),
        Materialized.<String, String, KeyValueStore<Bytes, byte[]>>as("timjson-ktable-store")
            .withKeySerde(Serdes.String()).withValueSerde(Serdes.String()));

    return builder.build();
  }

  /**
   * Query the KTable store by a specified UUID.
   *
   * @param uuid The specified UUID to query for.
   **/
  public String query(String uuid) {
    try {
      ReadOnlyKeyValueStore<String, String> keyValueStore = streams
          .store(StoreQueryParameters.fromNameAndType("timjson-ktable-store",
          QueryableStoreTypes.keyValueStore()));
      String value = keyValueStore.get(uuid);

      int retries = 5;
      int retryDelayMs = 100;
      int attempt = 0;
      // Retry offset in case the KTable is not yet populated with the UUID
      while (value == null && attempt < retries) {
        log.debug("No value found for UUID in TIM topology k-table: {}, retrying... (attempt {}/{})", uuid, attempt + 1, retries);
        try {
          Thread.sleep(retryDelayMs);
        } catch (InterruptedException ie) {
          Thread.currentThread().interrupt();
          break;
        }
        value = keyValueStore.get(uuid);
        attempt++;
      }

      if (value == null) {
        log.warn("No value found for UUID in TIM topology k-table after {} retries: {}", retries, uuid);
        return null;
      }

      // Push a tombstone (null value) for this key to the ktableTopic to remove it
      // from the KTable
      tombstonePublisher.send(this.ktableTopic, uuid, null).whenCompleteAsync((result, error) -> {
        if (error != null) {
          log.error("Failed to send TIM topology tombstone for key {}: {}", uuid, error.getMessage());
        } else {
          log.debug("TIM topology tombstone sent for key {}", uuid);
        }
      });

      return value;
    } catch (Exception e) {
      log.error("Error querying or removing UUID {} from TIM topology k-table: {}", uuid, e.getMessage(), e);
      return null;
    }
  }
}